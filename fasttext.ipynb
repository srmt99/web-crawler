{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext_trainer2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PMTFEoIU3e4",
        "colab_type": "text"
      },
      "source": [
        "# downloading and installing fastext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7jEXE_8I5uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/facebookresearch/fastText.git\n",
        "% cd fastText\n",
        "! mkdir build\n",
        "% cd build\n",
        "! cmake ..\n",
        "! make && make install\n",
        "% cd ..\n",
        "% cd ..\n",
        "! mkdir result\n",
        "! pip install fasttext\n",
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTy44mfeVIVU",
        "colab_type": "text"
      },
      "source": [
        "#(optional) creaing the input.txt\n",
        "downloading the raw text of a persian raw text corpus.\n",
        "\n",
        "**NOTE**: it is recommended that you don't download the whole file which is roughly 70 GB , instead stop the execution after the downloaded volume satisfies your need. by default we'll need about 5 GB so you could stop the excution of the cell after it has downloaded about 6 GB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhzeVaI4hsDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/danielk-files/farsi-text/merged_files/all_text_merged_cleaned.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg9oRYWUDk7m",
        "colab_type": "text"
      },
      "source": [
        "creating the input from the raw text.\n",
        "\n",
        "size of the input.txt is determined by **input_size** in GB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLwsR7MDU0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 5 # input by GB (~= 570 Million words, 100k unique words)\n",
        "\n",
        "bytes_to_copy = (input_size) * (10**9) * (0.6)\n",
        "copied_size = 0\n",
        "with open('input.txt','a',encoding=\"UTF-8\")as w:\n",
        "  with open('all_text_merged_cleaned.txt','r',encoding=\"UTF-8\")as r:\n",
        "    while True:\n",
        "      chunk = r.read(10000000)\n",
        "      if not chunk or copied_size >= bytes_to_copy:\n",
        "        break\n",
        "      copied_size += 10000000\n",
        "      w.write(chunk)\n",
        "      print(f\"\\r input_size ~= {str((copied_size/1000000)/(0.6))[:6]} MB\", end=\"\")\n",
        "print(\"\\ninput.txt is ready\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syrklFzMexk6",
        "colab_type": "text"
      },
      "source": [
        "# training the model\n",
        "once you have you data in an **input.txt** you can run the below cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMffjJbot2YJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_name = \"/content/result/per_model_\"\n",
        "print(output_name)\n",
        "! '/content/fastText/build/fasttext' skipgram -input '/content/input.txt' -output $output_name -epoch 5 -minn 3 -maxn 5 -dim 100 -lr 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPAhL_YyJHHD",
        "colab_type": "text"
      },
      "source": [
        "# loading the model\n",
        "then testing on some random words to check it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvKoWozBwHTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = fasttext.load_model(output_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2en6wCGKL9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.get_nearest_neighbors('همسر'))\n",
        "print(model.get_nearest_neighbors('مرد'))\n",
        "print(model.get_nearest_neighbors('امام'))\n",
        "print(model.get_nearest_neighbors('تره'))\n",
        "print(model.get_nearest_neighbors('گلابی'))\n",
        "print(model.get_nearest_neighbors('سیب'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aINagUPxNESu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.get_analogies(\"تهران\", \"ایران\", \"آلمان\"))\n",
        "print(\"->برلین\")\n",
        "print(model.get_analogies(\"تهران\", \"ایران\", \"فرانسه\"))\n",
        "print(\"->پاریس\")\n",
        "print(model.get_analogies(\"تهران\", \"ایران\", \"انگلستان\"))\n",
        "print(\"->لندن\")\n",
        "print(model.get_analogies(\"تهران\", \"ایران\", \"آمریکا\"))\n",
        "print(\"->واشنگتن\")\n",
        "print(model.get_analogies(\"پسر\", \"مرد\", \"زن\"))\n",
        "print(\"->دختر\")\n",
        "print(model.get_analogies(\"ملکه\", \"پادشاه\", \"شوهر\"))\n",
        "print(\"->زن\")\n",
        "print(model.get_analogies(\"فرزند\", \"پدر\", \"پدربزرگ\"))\n",
        "print(\"->پدر\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1Zz4SJO2Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# printing the distance between any two word vectors\n",
        "x = model.get_word_vector(\"زن\")\n",
        "y = model.get_word_vector(\"مرد\")\n",
        "print(np.linalg.norm(x-y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcH_WNkfgKdB",
        "colab_type": "text"
      },
      "source": [
        "*(also optional)* : the below code downloads the **already trained** persian fastext model. (on wikipidia data, you can check the details here: https://fasttext.cc/docs/en/crawl-vectors.html)\n",
        "\n",
        "the model would then be in a **wiki.fa.bin** file.\n",
        "\n",
        "the word vectors would be in a **wiki.fa.vec** file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4vIcLpyvZZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.fa.zip\n",
        "!unzip wiki.fa.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
